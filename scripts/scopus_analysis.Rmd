---
title: "scopus_analysis"
author: "daniellembecker"
date: "2024-02-01"
output: html_document
---

# Using the analysis output from [Scopus](https://www.scopus.com/term/analyzer.uri?sort=plf-f&src=s&sid=c3cad66d9c803eb9e767bdd52c487fb7&sot=a&sdt=a&sl=16&s=ALL%28sealifebase%29&origin=resultslist&count=10&analyzeResults=Analyze+results) where I searched SeaLifeBase citations.


# Load libraries

```{r}
library(ggplot2)
library(ggthemes)
library(tidyverse)
library(maps)
library(dplyr)
library(utils)
install.packages(c("leaflet"))
library(leaflet)
```

# Load all data files

```{r}

# Specify the folder path
folder_path <- "data/scopus_group_data/"

# Get a list of all CSV files in the folder
csv_files <- list.files(folder_path, pattern = "\\.csv$", full.names = TRUE)

# Read and skip the first seven rows for each CSV file, store in a list
all_data <- map(csv_files, ~{
  current_data <- read_csv(.x, skip = 7)
  # Rename the second column to the number of documents
  colnames(current_data)[2] <- 'number_documents'
  current_data
})

#name individual files
affiliation <- all_data[[1]]
author <- all_data[[2]]
country <- all_data[[3]]
doctype <- all_data[[4]]
funding.sponsor <- all_data[[5]]
# Rename the first column to 'funding_sponsor'
colnames(funding.sponsor)[1] <- 'funding_sponsor'
source <- all_data[[6]]
subject <- all_data[[7]]
year <- all_data[[8]]

# Save each data frame to a separate CSV file
save_data_frame <- function(data_frame, file_name) {
  output_file <- file.path("output/scopus_csv/", paste0(file_name, ".csv"))
  write.csv(data_frame, file = output_file, row.names = FALSE)
}

# Save each data frame
save_data_frame(affiliation, "affiliation")
save_data_frame(author, "author")
save_data_frame(country, "country")
save_data_frame(doctype, "doctype")
save_data_frame(funding.sponsor, "funding_sponsor")
save_data_frame(source, "source")
save_data_frame(subject, "subject")
save_data_frame(year, "year")

```


# Figure 1 for SeaLifeBase
```{r}

# Create a bar chart
year.plot <- year %>%
  ggplot(aes(x = YEAR, y = number_documents)) +
  geom_line() + 
  geom_point() +
  theme_classic() +
    theme(
    axis.text.x = element_text(angle = 0, margin = margin(t = 10, b = 10)),
    axis.title = element_text(size = 16),
    axis.text = element_text(size = 16),
    plot.margin = margin(t = 30, r = 40)) + # Adjusted top and right margi
  ylab("Scopus Citations") +
  xlab("Year") +
  scale_x_continuous(
    breaks = seq(2008, 2023, by = 1),  # Include all years from 2008 to 2023
    limits = c(2008, 2023),  # Adjusted limits
    expand = c(0, 0)) +
  coord_cartesian(clip = 'off') + #adjusts the cutoff so geom points stay intact
  scale_y_continuous(
    limits = c(0, 90),
    breaks = seq(0, 90, by = 10),
    expand = c(0, 0));year.plot

# Save the ggplot to a file (e.g., in PNG format)
ggsave("output/scopus_plots/year_output.png", plot = year.plot, width = 15, height = 8, dpi = 300)

```

# Comparing two citation lists generated by scopus for SeaLifeBase, first is 404 citations because we searched SeaLifeBase only, the 325 list is a search for SeaLifeBase and Palomares and Pauly

```{r}
#read in two data frames for comparison of citations

# Assuming your CSV file is in the working directory
sealifebase_325 <- read.csv("data/citation_list_master/scopus_extracat_citations_325.csv")

sealifebase_404 <- read.csv("data/citation_list_master/scopus_sealifebase_404.csv")

#found zero duplicates in either dataframe

duplicates <- duplicated(sealifebase_404)

print(sealifebase_404[duplicates, ])

duplicates <- duplicated(sealifebase_325)

print(sealifebase_325[duplicates, ])

# Find citations that are in df1 but not in df2
unique_to_df1 <- anti_join(sealifebase_325, sealifebase_404)

# Print the results
cat("Citations unique to df1:", nrow(unique_to_df1), "\n")
print(unique_to_df1)
#9

# Find citations that are in df2 but not in df1
unique_to_df2 <- anti_join(sealifebase_404, sealifebase_325)

# Print the results
cat("\nCitations unique to df2:", nrow(unique_to_df2), "\n")
print(unique_to_df2)
#88

# Find citations that are common to both data frames
common_citations <- intersect(sealifebase_325, sealifebase_404)

# Print the results
cat("\nCommon citations:", nrow(common_citations), "\n")
print(common_citations)
#316

#first checked 9 citation DOIs from df1 online to confirm sealifebase is mentioned in the citation
#then checked 88 citation DOIs from df2 online to confirm sealifebase is mentioned in the citation 
#through all citations, confirmed all are included in the 404 list and all are correct in including SeaLifeBase

# I confirmed all the unique citations in the 325 dataframe were included in the 404 dataframe just with slight variations in title or author, so 404 dataframe is the most commprehensive list 



```

# Make geographical bubble map of distribution and number of douments in different countries
```{r}

#load bubble map data
bub.dat <- read_csv("output/scopus_csv/country_bubblemap.csv")

# create data for world coordinates using map_data() function 
world_coordinates <- map_data("world") 
  
# create world map using ggplot() function 
# geom_map() function takes world coordinates as input to plot world map color parameter determines the color of borders in map fill parameter determines the color of fill in map size determines the thickness of border in map 

ggplot() + 
  geom_map(data = world_coordinates, map = world_coordinates, 
    aes(long, lat, map_id = region), fill= "cadetblue2")+ 
  geom_point(data = bub.dat, aes(lon, lat, color = documents, size=size), alpha = 1) +  # geom_point function is used to plot scatter plot on top of world map 
theme_bw() +  # Apply black and white theme
  theme(legend.position = "none") # legend.position as none removes the legend 

```





